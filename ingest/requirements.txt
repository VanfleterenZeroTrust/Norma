import os
import glob
from dotenv import load_dotenv
from fastembed import TextEmbedding
from azure.core.credentials import AzureKeyCredential
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.indexes.models import (
    SearchIndex, SimpleField, SearchFieldDataType, SearchField, VectorSearch
)
from azure.search.documents import SearchClient
from chunkers import pdf_to_chunks

# Charger les variables d’environnement (.env)
load_dotenv()

SEARCH_ENDPOINT = os.environ["AZURE_SEARCH_ENDPOINT"]
SEARCH_KEY = os.environ["AZURE_SEARCH_ADMIN_KEY"]
INDEX_NAME = os.environ.get("AZURE_SEARCH_INDEX", "docs")

# === Embeddings légers avec FastEmbed ===
EMBED_MODEL_ID = os.environ.get(
    "EMBEDDER_MODEL_ID", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
)
VECTOR_DIM = 384  # Taille du vecteur pour ce modèle
_embedder = TextEmbedding(model_name=EMBED_MODEL_ID)

def embed_texts(texts):
    # FastEmbed renvoie un générateur -> on le convertit en liste
    return [vec for vec in _embedder.embed(texts, batch_size=64)]

# === Création (ou recréation) de l’index ===
idx_client = SearchIndexClient(SEARCH_ENDPOINT, AzureKeyCredential(SEARCH_KEY))

fields = [
    SimpleField(name="id", type=SearchFieldDataType.String, key=True),
    SearchField(name="content", type=SearchFieldDataType.String, searchable=True),
    SearchField(
        name="embedding",
        type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
        searchable=True,
        vector_search_dimensions=VECTOR_DIM,
        vector_search_profile_name="vector-profile",
    ),
]

# Compatibilité selon version du SDK Azure
try:
    from azure.search.documents.indexes.models import VectorSearchAlgorithmConfiguration as _Algo
except ImportError:
    from azure.search.documents.indexes.models import HnswAlgorithmConfiguration as _Algo

vector_search = VectorSearch(algorithm_configurations=[_Algo(name="hnsw")])
index = SearchIndex(name=INDEX_NAME, fields=fields, vector_search=vector_search)

print(f"Creating index '{INDEX_NAME}'...")
try:
    idx_client.delete_index(INDEX_NAME)
except Exception:
    pass
idx_client.create_index(index)

# === Lecture des PDFs et création des chunks ===
docs = []
for path in glob.glob("./data/*.pdf"):
    print(f"Processing {path} ...")
    for ch in pdf_to_chunks(path):
        docs.append(ch)

print(f"Total chunks to upload: {len(docs)}")

# === Embedding + Upload par lots ===
client = SearchClient(SEARCH_ENDPOINT, INDEX_NAME, AzureKeyCredential(SEARCH_KEY))
BATCH = 32
for i in range(0, len(docs), BATCH):
    batch = docs[i : i + BATCH]
    embs = embed_texts([d["text"] for d in batch])
    for d, e in zip(batch, embs):
        d["content"] = d.pop("text")
        d["embedding"] = e
    client.upload_documents(batch)
    print(f"Uploaded {len(batch)} docs ({i + len(batch)}/{len(docs)})")

print("✅ Done! Index built successfully.")
